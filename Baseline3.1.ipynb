{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline de algoritmos de xtracción de palabras clave"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmos básicos: TextRank y Fractalidad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importes para librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "from math import sqrt\n",
    "import string\n",
    "# import csv\n",
    "import operator\n",
    "# import random\n",
    "import pandas as pd\n",
    "#librerias necesarias para text rank\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import spacy\n",
    "#import nlp\n",
    "\n",
    "#Listado de STOPWORDS dependiendo del lenguaje\n",
    "#from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.es.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting es-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_core_news_sm')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de la clase TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRank4Keyword():\n",
    "    \"\"\"Extract keywords from text\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.d = 0.85 # damping coefficient, usually is .85\n",
    "        self.min_diff = 1e-5 # convergence threshold\n",
    "        self.steps = 100 # iteration steps\n",
    "        self.node_weight = None # save keywords and its weight\n",
    "\n",
    "\n",
    "    def set_stopwords(self, stopwords):\n",
    "        \"\"\"Set stop words\"\"\"\n",
    "        for word in STOP_WORDS.union(set(stopwords)):\n",
    "            lexeme = nlp.vocab[word]\n",
    "            lexeme.is_stop = True\n",
    "\n",
    "    def sentence_segment(self, doc, candidate_pos, lower):\n",
    "        \"\"\"Store those words only in cadidate_pos\"\"\"\n",
    "        sentences = []\n",
    "        for sent in doc.sents:\n",
    "            selected_words = []\n",
    "            for token in sent:\n",
    "                # Store words only with cadidate POS tag\n",
    "                if token.pos_ in candidate_pos and token.is_stop is False:\n",
    "                    if lower is True:\n",
    "                        selected_words.append(token.text.lower())\n",
    "                    else:\n",
    "                        selected_words.append(token.text)\n",
    "            sentences.append(selected_words)\n",
    "        return sentences\n",
    "\n",
    "    def get_vocab(self, sentences):\n",
    "        \"\"\"Get all tokens\"\"\"\n",
    "        vocab = OrderedDict()\n",
    "        i = 0\n",
    "        for sentence in sentences:\n",
    "            for word in sentence:\n",
    "                if word not in vocab:\n",
    "                    vocab[word] = i\n",
    "                    i += 1\n",
    "        return vocab\n",
    "\n",
    "    def get_token_pairs(self, window_size, sentences):\n",
    "        \"\"\"Build token_pairs from windows in sentences\"\"\"\n",
    "        token_pairs = list()\n",
    "        for sentence in sentences:\n",
    "            for i, word in enumerate(sentence):\n",
    "                for j in range(i+1, i+window_size):\n",
    "                    if j >= len(sentence):\n",
    "                        break\n",
    "                    pair = (word, sentence[j])\n",
    "                    if pair not in token_pairs:\n",
    "                        token_pairs.append(pair)\n",
    "        return token_pairs\n",
    "\n",
    "    def symmetrize(self, a):\n",
    "        return a + a.T - np.diag(a.diagonal())\n",
    "\n",
    "    def get_matrix(self, vocab, token_pairs):\n",
    "        \"\"\"Get normalized matrix\"\"\"\n",
    "        # Build matrix\n",
    "        vocab_size = len(vocab)\n",
    "        g = np.zeros((vocab_size, vocab_size), dtype='float')\n",
    "        for word1, word2 in token_pairs:\n",
    "            i, j = vocab[word1], vocab[word2]\n",
    "            g[i][j] = 1\n",
    "\n",
    "        # Get Symmeric matrix\n",
    "        g = self.symmetrize(g)\n",
    "\n",
    "        # Normalize matrix by column\n",
    "        norm = np.sum(g, axis=0)\n",
    "        g_norm = np.divide(g, norm, where=norm!=0) # this is ignore the 0 element in norm\n",
    "\n",
    "        return g_norm\n",
    "\n",
    "\n",
    "    def get_keywords(self, number=10):\n",
    "        \"\"\"Print top number keywords\"\"\"\n",
    "        keysw={}\n",
    "        node_weight = OrderedDict(sorted(self.node_weight.items(), key=lambda t: t[1], reverse=True))\n",
    "        for i, (key, value) in enumerate(node_weight.items()):\n",
    "            keysw[key] =value\n",
    "            if i > number:\n",
    "                break\n",
    "        return keysw\n",
    "\n",
    "\n",
    "    def analyze(self, text,\n",
    "                candidate_pos=['NOUN', 'PROPN'],\n",
    "                window_size=4, lower=False, stopwords=list()):\n",
    "        \"\"\"Main function to analyze text\"\"\"\n",
    "\n",
    "        # Set stop words\n",
    "        self.set_stopwords(stopwords)\n",
    "\n",
    "        # Pare text by spaCy\n",
    "        doc = nlp(text)\n",
    "\n",
    "        # Filter sentences\n",
    "        sentences = self.sentence_segment(doc, candidate_pos, lower) # list of list of words\n",
    "\n",
    "        # Build vocabulary\n",
    "        vocab = self.get_vocab(sentences)\n",
    "\n",
    "        # Get token_pairs from windows\n",
    "        token_pairs = self.get_token_pairs(window_size, sentences)\n",
    "\n",
    "        # Get normalized matrix\n",
    "        g = self.get_matrix(vocab, token_pairs)\n",
    "\n",
    "        # Initionlization for weight(pagerank value)\n",
    "        pr = np.array([1] * len(vocab))\n",
    "\n",
    "        # Iteration\n",
    "        previous_pr = 0\n",
    "        for epoch in range(self.steps):\n",
    "            pr = (1-self.d) + self.d * np.dot(g, pr)\n",
    "            if abs(previous_pr - sum(pr))  < self.min_diff:\n",
    "                break\n",
    "            else:\n",
    "                previous_pr = sum(pr)\n",
    "\n",
    "        # Get weight for each node\n",
    "        node_weight = dict()\n",
    "        for word, index in vocab.items():\n",
    "            node_weight[word] = pr[index]\n",
    "\n",
    "        self.node_weight = node_weight\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de la función Grado de Fractalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solamente se calcula el grado de fractalidad de las palabras que tengan mas de uno de frecuencia\n",
    "def fractalidad(palabras,vocabulario,frec,dist):\n",
    "    N=len(palabras)                                     #El número de tokens de todo el texto\n",
    "    gf={}\n",
    "    cajas_index=set()\n",
    "    voc=[]                                             #la variable voc contendra cada sintagma con frecuencia mayor que 1, por que las otras palabras tendrán 0 de grado de fractaldiad\n",
    "    for p in vocabulario:                              #Esto se puede hacer fuera del algoritmo, pero se incluye para evitar ese calculo innecesario\n",
    "        if(p not in voc):\n",
    "            if(frec[p]>1):\n",
    "                if(p not in STOP_WORDS):\n",
    "                    if(len(p)>1):\n",
    "                        voc.append(p)\n",
    "    # print(\"Text size: \",N)\n",
    "    # print(\"Vocabulary: \",len(voc))\n",
    "    for p in voc:\n",
    "        rcajas=dist[p]\n",
    "        M=frec[p]\n",
    "        dfw=0.0\n",
    "        nsh=0.0\n",
    "        for s in range(1,N+1):\n",
    "            noc=0\n",
    "            for e in rcajas:\n",
    "                cajas_index.add(ceil(int(e)/s))\n",
    "            noc=len(cajas_index)\n",
    "            cajas_index.clear()\n",
    "            ns=N/s\n",
    "            if(M<=ns):\n",
    "                nsh=M\n",
    "            else:\n",
    "                nsh=M/(1+(M-1)/(N-1)*(s-1))\n",
    "            dfw=dfw+fabs(log(nsh/noc))\n",
    "        gf[p]=dfw\n",
    "    return gf    #regresamos un diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribucion(palabras,vocabulario):\n",
    "    N=len(palabras)\n",
    "    ncajas=[]\n",
    "    cajas={}\n",
    "    frecuencias={}\n",
    "    for p in vocabulario:\n",
    "        ncajas.clear()\n",
    "        i=0\n",
    "        M=palabras.count(p)\n",
    "        while(i<N):\n",
    "            if(p == palabras[i]):\n",
    "                ncajas.append(i+1)\n",
    "            i=i+1\n",
    "        frecuencias[p]=M\n",
    "        cajas[p]=ncajas[:]\n",
    "    return frecuencias,cajas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de archivo de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de archivo para generación de vocabulario\n",
    "def cargar_datos(filename):\n",
    "    textopos = []\n",
    "    textoneg =[]\n",
    "    with open(filename, encoding=\"utf-8-sig\") as f:\n",
    "        texto = pd.read_csv(f)\n",
    "        for _, r in texto.iterrows():\n",
    "            if r['ds0':'ds3'].sum(axis=0) == 1:\n",
    "                textoneg.append(r['Texto'])\n",
    "            else:\n",
    "                textopos.append(r['Texto'])\n",
    "        for row in textopos:\n",
    "            #Pasar a minusculas\n",
    "            row = ' '.join(row)\n",
    "            row = row.lower()\n",
    "    #Eliminar puntuación\n",
    "        for row in textoneg:\n",
    "            row = ' '.join(row)\n",
    "            row = row.lower()\n",
    "    textopos =' '.join(textopos)\n",
    "    textoneg=' '.join(textoneg)\n",
    "    textopos = textopos.translate(str.maketrans('', '', string.punctuation))\n",
    "    textoneg = textoneg.translate(str.maketrans('', '', string.punctuation))\n",
    "    textopos = textopos.translate(str.maketrans('', '', '¿?¡!.:,;—“”0123456789’'))\n",
    "    textoneg = textoneg.translate(str.maketrans('', '', '¿?¡!.:,;—“”0123456789’'))\n",
    "    palabraspos = textopos.split()\n",
    "    palabrasneg = textoneg.split()\n",
    "    textop=\"\"\n",
    "    texton=\"\"\n",
    "    #rearmamos el texto debido a que existen carácteres especiales\n",
    "    for w in palabraspos:\n",
    "        textop=textop+w+' '\n",
    "    for w in palabrasneg:\n",
    "        texton=texton+w+' '\n",
    "    return textop, texton"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lee_documento(filename='NULL',texto=''):\n",
    "    if filename != 'NULL':\n",
    "        textop, texton=cargar_datos(filename)\n",
    "    textop = textop.lower()\n",
    "    texton = texton.lower()\n",
    "    #obtenemos el vocabulario\n",
    "    tokensp=textop.split()\n",
    "    vocabulariop=[]\n",
    "    vocabularion=[]\n",
    "    tokensn = texton.split()\n",
    "    for t in tokensp:\n",
    "        if(t not in vocabulariop):\n",
    "            vocabulariop.append(t)\n",
    "    for t in tokensn:\n",
    "        if(t not in vocabularion):\n",
    "            vocabularion.append(t)\n",
    "    #variables de procesamiento\n",
    "    distp={}\n",
    "    distn={}\n",
    "    frecn={}\n",
    "    frecp={}\n",
    "    frecp,distp=distribucion(tokensp,vocabulariop)\n",
    "    frecn, distn = distribucion(tokensn, vocabularion)\n",
    "    return frecp,distp,tokensp,vocabulariop,textop,frecn,distn,tokensn,vocabularion,texton"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecución de algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de documento para el corpus de suicidio\n",
    "frecp,distp,tokensp,vocabulariop,textop,frecn,distn,tokensn,vocabularion,texton = lee_documento('/home/m/MGP/maestria/proyecto_tesis/baseline/Datasets/SMS_DATA_ORIGINAL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frecuencias: 9737\n",
      "Distribuciones:  9737\n",
      "Tokens:  147703\n",
      "Vocabulario:  9737\n",
      "Texto:  786991\n"
     ]
    }
   ],
   "source": [
    "print('Frecuencias:', len(frecp))\n",
    "print(\"Distribuciones: \", len(distp))\n",
    "print(\"Tokens: \", len(tokensp))\n",
    "print('Vocabulario: ', len(vocabulariop))\n",
    "print('Texto: ', len(textop))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frecuencias: 7377\n",
      "Distribuciones:  7377\n",
      "Tokens:  98983\n",
      "Vocabulario:  7377\n",
      "Texto:  515324\n"
     ]
    }
   ],
   "source": [
    "print('Frecuencias:', len(frecn))\n",
    "print(\"Distribuciones: \", len(distn))\n",
    "print(\"Tokens: \", len(tokensn))\n",
    "print('Vocabulario: ', len(vocabularion))\n",
    "print('Texto: ', len(texton))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grado de Fractalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ejecución de algoritmo Grado de Fractalidad\n",
    "def grado_de_fractalidad(tokens,vocabulario,frec,dist,regresa_kw=False,regresa_df=True,top_n=np.inf,escribe_arch=False):\n",
    "    frac_x=fractalidad(tokens,vocabulario,frec,dist)\n",
    "    sorted_x = sorted(frac_x.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    # print('Time GF: '+str(elapsed_time))\n",
    "\n",
    "    #Imprimir y guardar resultados de GF\n",
    "    if regresa_df:\n",
    "        if top_n != np.inf:\n",
    "            df=[[t[0],frec[t[0]], t[1], t[1]*log10(frec[t[0]])] for t in sorted_x[:top_n]]\n",
    "        else:\n",
    "            df=[[t[0],frec[t[0]], t[1], t[1]*log10(frec[t[0]])] for t in sorted_x]\n",
    "        #Ordenar resultados por medida combinada\n",
    "        df.sort(key=lambda x: x[3],reverse=True)\n",
    "        if regresa_kw==False:\n",
    "            df = [dato[0] for dato in df]\n",
    "            by_MC=pd.DataFrame(df, columns=['word'])\n",
    "        else:\n",
    "            by_MC=pd.DataFrame(df, columns=['word','frecuency','Degree_of_fractality','Combined_measure'])\n",
    "        if escribe_arch:\n",
    "            by_MC.to_csv('GF.csv')\n",
    "    else:\n",
    "        if top_n != np.inf:\n",
    "            df=[[t[0],frec[t[0]], t[1], t[1]*log10(frec[t[0]])] for t in sorted_x[:top_n]]\n",
    "        else:\n",
    "            df=[[t[0],frec[t[0]], t[1], t[1]*log10(frec[t[0]])] for t in sorted_x]\n",
    "        #Ordenar resultados por medida combinada\n",
    "        df.sort(key=lambda x: x[3],reverse=True)\n",
    "        if regresa_kw==False:\n",
    "            by_MC = [dato[0] for dato in df]\n",
    "        else:\n",
    "            by_MC = df\n",
    "        if escribe_arch:\n",
    "            print('\\nNo se tiene implementada la escritura de archivo cuando regresa_df==False\\n')\n",
    "    return by_MC\n",
    "\n",
    "def use_gf(texto,regresa_kw=False,regresa_df=False,top_n=np.inf,escribe_arch=False):\n",
    "    tokens=texto.split()\n",
    "    vocabulario=[]\n",
    "    for t in tokens:\n",
    "        if(t not in vocabulario):\n",
    "            vocabulario.append(t)\n",
    "    #variables de procesamiento\n",
    "    dist={}\n",
    "    frec={}\n",
    "    frec,dist=distribucion(tokens,vocabulario)\n",
    "    df = grado_de_fractalidad(tokens,vocabulario,frec,dist,regresa_kw,regresa_df,top_n,escribe_arch)\n",
    "    return df\n",
    "\n",
    "fractPositivas = use_gf(textop,regresa_kw=True,regresa_df=True,top_n=338)\n",
    "fractNegativas = use_gf(texton,regresa_kw=True,regresa_df=True,top_n=338)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frecuency</th>\n",
       "      <th>Degree_of_fractality</th>\n",
       "      <th>Combined_measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>caca</td>\n",
       "      <td>23</td>\n",
       "      <td>125172.298308</td>\n",
       "      <td>170450.602904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recogido</td>\n",
       "      <td>13</td>\n",
       "      <td>117297.911710</td>\n",
       "      <td>130663.228989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>epigastrio</td>\n",
       "      <td>13</td>\n",
       "      <td>114829.319993</td>\n",
       "      <td>127913.357656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rituales</td>\n",
       "      <td>12</td>\n",
       "      <td>116211.203602</td>\n",
       "      <td>125412.951508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ok</td>\n",
       "      <td>12</td>\n",
       "      <td>115319.796097</td>\n",
       "      <td>124450.961246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>reseñable</td>\n",
       "      <td>2</td>\n",
       "      <td>60439.256235</td>\n",
       "      <td>18194.029042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>cuadro</td>\n",
       "      <td>2</td>\n",
       "      <td>60437.488057</td>\n",
       "      <td>18193.496768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>hinchados</td>\n",
       "      <td>2</td>\n",
       "      <td>60422.246861</td>\n",
       "      <td>18188.908711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>rodaje</td>\n",
       "      <td>2</td>\n",
       "      <td>60409.077065</td>\n",
       "      <td>18184.944207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>procastrinador</td>\n",
       "      <td>2</td>\n",
       "      <td>60409.077065</td>\n",
       "      <td>18184.944207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               word  frecuency  Degree_of_fractality  Combined_measure\n",
       "0              caca         23         125172.298308     170450.602904\n",
       "1          recogido         13         117297.911710     130663.228989\n",
       "2        epigastrio         13         114829.319993     127913.357656\n",
       "3          rituales         12         116211.203602     125412.951508\n",
       "4                ok         12         115319.796097     124450.961246\n",
       "..              ...        ...                   ...               ...\n",
       "333       reseñable          2          60439.256235      18194.029042\n",
       "334          cuadro          2          60437.488057      18193.496768\n",
       "335       hinchados          2          60422.246861      18188.908711\n",
       "336          rodaje          2          60409.077065      18184.944207\n",
       "337  procastrinador          2          60409.077065      18184.944207\n",
       "\n",
       "[338 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fractPositivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frecuency</th>\n",
       "      <th>Degree_of_fractality</th>\n",
       "      <th>Combined_measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lavadora</td>\n",
       "      <td>33</td>\n",
       "      <td>60811.061206</td>\n",
       "      <td>92342.444141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ansium</td>\n",
       "      <td>28</td>\n",
       "      <td>60280.895388</td>\n",
       "      <td>87235.981897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tendido</td>\n",
       "      <td>22</td>\n",
       "      <td>59131.211519</td>\n",
       "      <td>79379.079488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fregado</td>\n",
       "      <td>17</td>\n",
       "      <td>63527.341626</td>\n",
       "      <td>78167.148981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tripa</td>\n",
       "      <td>17</td>\n",
       "      <td>57335.809170</td>\n",
       "      <td>70548.784550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>techo</td>\n",
       "      <td>2</td>\n",
       "      <td>39968.089945</td>\n",
       "      <td>12031.593943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>puertas</td>\n",
       "      <td>2</td>\n",
       "      <td>39950.068118</td>\n",
       "      <td>12026.168832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>demoníacos</td>\n",
       "      <td>2</td>\n",
       "      <td>39847.482335</td>\n",
       "      <td>11995.287435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>chispeaba</td>\n",
       "      <td>2</td>\n",
       "      <td>39837.085128</td>\n",
       "      <td>11992.157563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>gabapentina</td>\n",
       "      <td>2</td>\n",
       "      <td>39813.637835</td>\n",
       "      <td>11985.099225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  frecuency  Degree_of_fractality  Combined_measure\n",
       "0       lavadora         33          60811.061206      92342.444141\n",
       "1         ansium         28          60280.895388      87235.981897\n",
       "2        tendido         22          59131.211519      79379.079488\n",
       "3        fregado         17          63527.341626      78167.148981\n",
       "4          tripa         17          57335.809170      70548.784550\n",
       "..           ...        ...                   ...               ...\n",
       "333        techo          2          39968.089945      12031.593943\n",
       "334      puertas          2          39950.068118      12026.168832\n",
       "335   demoníacos          2          39847.482335      11995.287435\n",
       "336    chispeaba          2          39837.085128      11992.157563\n",
       "337  gabapentina          2          39813.637835      11985.099225\n",
       "\n",
       "[338 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fractNegativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guarda los resultados del grado de fractalidad en un CSV. Siempre hay que cambiar la versión y comentar para no sobreescribir\n",
    "# fractPositivas.to_csv('/home/m/MGP/maestria/proyecto_tesis/baseline/output/fractalidad_positivas_resultados_prueba2.csv')\n",
    "# fractNegativas.to_csv('/home/m/MGP/maestria/proyecto_tesis/baseline/output/fractalidad_negativas_resultados_prueba2.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambio del máximo de tamaño de texto para que quepa el corpus (1.3 millones)\n",
    "nlp.max_length = 1500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ejecución de algoritmo de TextRank\n",
    "# start_time = time()\n",
    "def use_TextRank(texto,regresa_kw=False,regresa_df=False,top_n=np.inf,escribe_arch=False):\n",
    "    tr4w = TextRank4Keyword()\n",
    "    tr4w.analyze(texto, candidate_pos = ['NOUN','PROPN'], window_size=4, lower=False)\n",
    "    kwTR=tr4w.get_keywords(100)\n",
    "\n",
    "    #Guardar resultados de TextRank\n",
    "    if regresa_df:\n",
    "        if top_n!=np.inf:\n",
    "            if regresa_kw==True:\n",
    "                salida = [[key, kwTR[key]] for key in kwTR.keys()][:top_n]\n",
    "                dftr=pd.DataFrame(salida, columns=['word', 'Index'])\n",
    "            else:\n",
    "                salida = list(kwTR.keys())[:top_n]\n",
    "                dftr=pd.DataFrame(salida, columns=['word'])\n",
    "        else:\n",
    "            if regresa_kw==True:\n",
    "                salida = [[key, kwTR[key]] for key in kwTR.keys()]\n",
    "                dftr=pd.DataFrame(salida, columns=['word', 'Index'])\n",
    "            else:\n",
    "                salida = list(kwTR.keys())\n",
    "                dftr=pd.DataFrame(salida, columns=['word'])\n",
    "    else:\n",
    "        if top_n!=np.inf:\n",
    "            if regresa_kw==True:\n",
    "                dftr = [[key, kwTR[key]] for key in kwTR.keys()][:top_n]\n",
    "            else:\n",
    "                dftr = list(kwTR.keys())[:top_n]\n",
    "        else:\n",
    "            if regresa_kw==True:\n",
    "                dftr = [[key, kwTR[key]] for key in kwTR.keys()]\n",
    "            else:\n",
    "                dftr = list(kwTR.keys())\n",
    "        # elapsed_time = time() - start_time\n",
    "        # print('Time TextRank: '+str(elapsed_time))\n",
    "        if escribe_arch:\n",
    "            dftr.to_csv('TextRank.csv')\n",
    "    return dftr\n",
    "\n",
    "trpos = use_TextRank(textop,top_n=338)\n",
    "trneg = use_TextRank(texton,top_n=338)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trabajo',\n",
       " 'cosas',\n",
       " 'casa',\n",
       " 'semana',\n",
       " 'tiempo',\n",
       " 'vida',\n",
       " 'ansiedad',\n",
       " 'ganas',\n",
       " 'horas',\n",
       " 'madre',\n",
       " 'noche',\n",
       " 'mañana',\n",
       " 'cabeza',\n",
       " 'problemas',\n",
       " 'familia',\n",
       " 'situación',\n",
       " 'sueño',\n",
       " 'miedo',\n",
       " 'medicación',\n",
       " 'momento',\n",
       " 'sensación',\n",
       " 'problema',\n",
       " 'dolor',\n",
       " 'ánimo',\n",
       " 'tratamiento',\n",
       " 'gente',\n",
       " 'pareja',\n",
       " 'años',\n",
       " 'hora',\n",
       " 'marido',\n",
       " 'mujer',\n",
       " 'padre',\n",
       " 'gracias',\n",
       " 'persona',\n",
       " 'general',\n",
       " 'cosa',\n",
       " 'doctora',\n",
       " 'momentos',\n",
       " 'tema',\n",
       " 'tensión',\n",
       " 'hija',\n",
       " 'comida',\n",
       " 'hijo',\n",
       " 'hijos',\n",
       " 'mes',\n",
       " 'vacaciones',\n",
       " 'consulta',\n",
       " 'hermana',\n",
       " 'cambio',\n",
       " 'intento',\n",
       " 'médico',\n",
       " 'cuestionario',\n",
       " 'pastillas',\n",
       " 'cambios',\n",
       " 'forma',\n",
       " 'pensamientos',\n",
       " 'semanas',\n",
       " 'cita',\n",
       " 'enfermedad',\n",
       " 'sábado',\n",
       " 'nervios',\n",
       " 'meses',\n",
       " 'amigos',\n",
       " 'falta',\n",
       " 'personas',\n",
       " 'cansancio',\n",
       " 'dolores',\n",
       " 'cuerpo',\n",
       " 'sigo',\n",
       " 'niño',\n",
       " 'lunes',\n",
       " 'rato',\n",
       " 'viernes',\n",
       " 'psiquiatra',\n",
       " 'miligramo',\n",
       " 'año',\n",
       " 'salud',\n",
       " 'hospital',\n",
       " 'hola',\n",
       " 'madrid',\n",
       " 'relación',\n",
       " 'amiga',\n",
       " 'mente',\n",
       " 'baja',\n",
       " 'cama',\n",
       " 'discusión',\n",
       " 'estrés',\n",
       " 'mundo',\n",
       " 'domingo',\n",
       " 'razón',\n",
       " 'tristeza',\n",
       " 'clase',\n",
       " 'actividades',\n",
       " 'pena',\n",
       " 'dosis',\n",
       " 'fuerzas',\n",
       " 'coche',\n",
       " 'calle',\n",
       " 'actividad',\n",
       " 'test',\n",
       " 'caso',\n",
       " 'lorazepam']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vida',\n",
       " 'casa',\n",
       " 'cosas',\n",
       " 'dolor',\n",
       " 'madre',\n",
       " 'cabeza',\n",
       " 'ansiedad',\n",
       " 'ganas',\n",
       " 'tiempo',\n",
       " 'gracias',\n",
       " 'semana',\n",
       " 'trabajo',\n",
       " 'problemas',\n",
       " 'noche',\n",
       " 'perro',\n",
       " 'medicación',\n",
       " 'años',\n",
       " 'persona',\n",
       " 'mañana',\n",
       " 'horas',\n",
       " 'comida',\n",
       " 'gente',\n",
       " 'miedo',\n",
       " 'cosa',\n",
       " 'familia',\n",
       " 'mierda',\n",
       " 'sensación',\n",
       " 'sueño',\n",
       " 'padre',\n",
       " 'cama',\n",
       " 'noches',\n",
       " 'hija',\n",
       " 'mundo',\n",
       " 'dolores',\n",
       " 'momento',\n",
       " 'cuerpo',\n",
       " 'hora',\n",
       " 'ánimo',\n",
       " 'situación',\n",
       " 'médico',\n",
       " 'problema',\n",
       " 'momentos',\n",
       " 'tensión',\n",
       " 'daño',\n",
       " 'pensamientos',\n",
       " 'hospital',\n",
       " 'intento',\n",
       " 'marido',\n",
       " 'dinero',\n",
       " 'pena',\n",
       " 'nervios',\n",
       " 'personas',\n",
       " 'tratamiento',\n",
       " 'sentido',\n",
       " 'hijos',\n",
       " 'pastillas',\n",
       " 'calle',\n",
       " 'salud',\n",
       " 'tristeza',\n",
       " 'enfermedad',\n",
       " 'sigo',\n",
       " 'culpa',\n",
       " 'fuerzas',\n",
       " 'año',\n",
       " 'pareja',\n",
       " 'resto',\n",
       " 'meses',\n",
       " 'discusiones',\n",
       " 'cambio',\n",
       " 'amiga',\n",
       " 'hijo',\n",
       " 'psiquiatra',\n",
       " 'coche',\n",
       " 'doctora',\n",
       " 'vueltas',\n",
       " 'depresión',\n",
       " 'rato',\n",
       " 'frío',\n",
       " 'pesadillas',\n",
       " 'amigos',\n",
       " 'vuelta',\n",
       " 'consulta',\n",
       " 'cita',\n",
       " 'hermana',\n",
       " 'mes',\n",
       " 'humor',\n",
       " 'caso',\n",
       " 'mente',\n",
       " 'cambios',\n",
       " 'esfuerzo',\n",
       " 'hermano',\n",
       " 'falta',\n",
       " 'ropa',\n",
       " 'tipo',\n",
       " 'padres',\n",
       " 'espalda',\n",
       " 'tema',\n",
       " 'ilusión',\n",
       " 'cara',\n",
       " 'baja',\n",
       " 'discusión',\n",
       " 'duermo']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guarda los resultados del TextRank en un txt. Siempre hay que cambiar la versión y comentar para no sobreescribir\n",
    "# with open('/home/m/MGP/maestria/proyecto_tesis/baseline/output/TextRank_resultados_positivos_prueba2.txt','w') as output:\n",
    "#     output.write(str(trpos))\n",
    "# with open('/home/m/MGP/maestria/proyecto_tesis/baseline/output/TextRank_resultados_negativos_prueba2.txt','w') as output:\n",
    "#     output.write(str(trneg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación de los resultados de fractalidad y TextRank con el conjunto de Palabras Prototípicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/m/MGP/maestria/proyecto_tesis/baseline/Palabras_proto/clinical-prescores.csv', encoding=\"utf-8-sig\") as f:\n",
    "        palabrasProto = pd.read_csv(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>word</th>\n",
       "      <th>c-prescore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>lormetazepam</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mg</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>mirtazapina</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>fluoxetina</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>alprazolam</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>334</td>\n",
       "      <td>aclaratorio</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>335</td>\n",
       "      <td>limpié</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>336</td>\n",
       "      <td>practicas</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>337</td>\n",
       "      <td>claros</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>338</td>\n",
       "      <td>convierte</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>339 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0          word  c-prescore\n",
       "0             0  lormetazepam        -5.0\n",
       "1             1            mg        -5.0\n",
       "2             2   mirtazapina        -5.0\n",
       "3             3    fluoxetina        -5.0\n",
       "4             4    alprazolam        -5.0\n",
       "..          ...           ...         ...\n",
       "334         334   aclaratorio         2.0\n",
       "335         335        limpié         2.0\n",
       "336         336     practicas         2.0\n",
       "337         337        claros         2.0\n",
       "338         338     convierte         2.0\n",
       "\n",
       "[339 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palabrasProto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creación de listas de las palabras positivas y negativas\n",
    "# positivas = []\n",
    "# negativas = []\n",
    "# for index, row in palabrasProto.iterrows():\n",
    "#     if row['pos-neg']==1:\n",
    "#         positivas.append(row['Palabra'])\n",
    "#     else:\n",
    "#         negativas.append(row['Palabra'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para crear la medida de Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Medida Jaccard que mide la proporción de elementos de un conjunto en otro\n",
    "def jaccard(s1: set, s2: set):\n",
    "    return len(s1 & s2) / len(s1 | s2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coinsidencia(conjuntoA, conjuntoB):\n",
    "    matches = []\n",
    "    for palabra in conjuntoA:\n",
    "        if palabra in conjuntoB:\n",
    "            matches.append(palabra)\n",
    "    conteo = len(matches)\n",
    "    return matches, conteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard de fractalidad positivas:  0.021116138763197588\n",
      "Jaccard de TextRank positivas:  0.02558139534883721\n",
      "Jaccard de fractalidad negativas:  0.022658610271903322\n",
      "Jaccard de TextRank negativas:  0.02320185614849188\n"
     ]
    }
   ],
   "source": [
    "jaccFractalidadPos = jaccard(set(palabrasProto['word']), set(fractPositivas['word']))\n",
    "jaccTRPos = jaccard(set(palabrasProto['word']), set(trpos))\n",
    "jaccFractalidadNeg = jaccard(set(palabrasProto['word']), set(fractNegativas['word']))\n",
    "jaccTRNeg = jaccard(set(palabrasProto['word']), set(trneg))\n",
    "# _, conteosTR = jaccard(texto, dftr)\n",
    "# _, conteosFract= jaccard(texto, list(df1['word']))\n",
    "# _, conteosProto= jaccard(texto, list(palabrasProto['Palabra']))\n",
    "\n",
    "print('Jaccard de fractalidad positivas: ', jaccFractalidadPos)\n",
    "\n",
    "print('Jaccard de TextRank positivas: ', jaccTRPos)\n",
    "\n",
    "\n",
    "print('Jaccard de fractalidad negativas: ', jaccFractalidadNeg)\n",
    "\n",
    "print('Jaccard de TextRank negativas: ', jaccTRNeg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "coinTRPos, conteosTRP = coinsidencia(list(palabrasProto['word']), trpos)\n",
    "coinTRNeg, conteosTRN = coinsidencia(list(palabrasProto['word']), trneg)\n",
    "coinFracPos, conteosFrP = coinsidencia(list(palabrasProto['word']), list(fractPositivas['word']))\n",
    "coinFracNeg, conteosFrN = coinsidencia(list(palabrasProto['word']), list(fractNegativas['word']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lorazepam', 'miligramo', 'dosis', 'noche', 'vida', 'hijo', 'padre', 'hermana', 'hija', 'marido', 'madre']\n",
      "Conteo de TextRank Pos: 11\n",
      "['noche', 'vida', 'hermano', 'hijo', 'padre', 'hermana', 'padres', 'hija', 'marido', 'madre']\n",
      "conteo de TextRank Neg. 10\n",
      "['sycrest', 'quetiapina', 'melatonina', 'risperdal', 'capsulas', 'diazepam', 'zolpidem', 'rubifen', 'acúfenos', 'calumnias', 'desconfío', 'quiste', 'interrupciones', 'manchado']\n",
      "Conteo de Fractalidad Pos 14\n",
      "['alprazolam', 'escitalopram', 'sycrest', 'trazodona', 'cymbalta', 'paroxetina', 'herida', 'espasmos', 'dolorido', 'monótono', 'novia', 'tíos', 'aprobado', 'tratamientos', 'colocado']\n",
      "Conteo Fractalidad Neg: 15\n"
     ]
    }
   ],
   "source": [
    "print(coinTRPos)\n",
    "print('Conteo de TextRank Pos:',conteosTRP)\n",
    "print(coinTRNeg)\n",
    "print('conteo de TextRank Neg.',conteosTRN)\n",
    "print(coinFracPos)\n",
    "print('Conteo de Fractalidad Pos',conteosFrP)\n",
    "print(coinFracNeg)\n",
    "print('Conteo Fractalidad Neg:',conteosFrN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Siguientes pasos\n",
    "\n",
    "- Probar sólo con una etiqueta\n",
    "- Probar con un modelo más pequeño para ver si funciona\n",
    "- Hacer una prueba con BeRT como viene usando los embedings de BETO y la tarea con un KeyBERT\n",
    "- Hacer una prueba con KeyBERT haciendo un finetuning de los embedings de BETO\n",
    "- Hablar con Ulises para ver la propuesta de la LSTM con atención\n",
    "- Hacer un análisis de las palabras prototípicas utilizadas con la base de datos de prototipicalidad\n",
    "- Hacer una prueba con un LLM (preguntar si con la API o directamente) y evaluar resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pb_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
