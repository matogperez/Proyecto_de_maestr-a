{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline de algoritmos de xtracción de palabras clave"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmos básicos: TextRank y Fractalidad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importes para librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "from math import sqrt\n",
    "import string\n",
    "# import csv\n",
    "import operator\n",
    "# import random\n",
    "import pandas as pd\n",
    "#librerias necesarias para text rank\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import spacy\n",
    "#import nlp\n",
    "\n",
    "#Listado de STOPWORDS dependiendo del lenguaje\n",
    "#from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.es.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting es-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_core_news_sm')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de la clase TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRank4Keyword():\n",
    "    \"\"\"Extract keywords from text\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.d = 0.85 # damping coefficient, usually is .85\n",
    "        self.min_diff = 1e-5 # convergence threshold\n",
    "        self.steps = 100 # iteration steps\n",
    "        self.node_weight = None # save keywords and its weight\n",
    "\n",
    "\n",
    "    def set_stopwords(self, stopwords):\n",
    "        \"\"\"Set stop words\"\"\"\n",
    "        for word in STOP_WORDS.union(set(stopwords)):\n",
    "            lexeme = nlp.vocab[word]\n",
    "            lexeme.is_stop = True\n",
    "\n",
    "    def sentence_segment(self, doc, candidate_pos, lower):\n",
    "        \"\"\"Store those words only in cadidate_pos\"\"\"\n",
    "        sentences = []\n",
    "        for sent in doc.sents:\n",
    "            selected_words = []\n",
    "            for token in sent:\n",
    "                # Store words only with cadidate POS tag\n",
    "                if token.pos_ in candidate_pos and token.is_stop is False:\n",
    "                    if lower is True:\n",
    "                        selected_words.append(token.text.lower())\n",
    "                    else:\n",
    "                        selected_words.append(token.text)\n",
    "            sentences.append(selected_words)\n",
    "        return sentences\n",
    "\n",
    "    def get_vocab(self, sentences):\n",
    "        \"\"\"Get all tokens\"\"\"\n",
    "        vocab = OrderedDict()\n",
    "        i = 0\n",
    "        for sentence in sentences:\n",
    "            for word in sentence:\n",
    "                if word not in vocab:\n",
    "                    vocab[word] = i\n",
    "                    i += 1\n",
    "        return vocab\n",
    "\n",
    "    def get_token_pairs(self, window_size, sentences):\n",
    "        \"\"\"Build token_pairs from windows in sentences\"\"\"\n",
    "        token_pairs = list()\n",
    "        for sentence in sentences:\n",
    "            for i, word in enumerate(sentence):\n",
    "                for j in range(i+1, i+window_size):\n",
    "                    if j >= len(sentence):\n",
    "                        break\n",
    "                    pair = (word, sentence[j])\n",
    "                    if pair not in token_pairs:\n",
    "                        token_pairs.append(pair)\n",
    "        return token_pairs\n",
    "\n",
    "    def symmetrize(self, a):\n",
    "        return a + a.T - np.diag(a.diagonal())\n",
    "\n",
    "    def get_matrix(self, vocab, token_pairs):\n",
    "        \"\"\"Get normalized matrix\"\"\"\n",
    "        # Build matrix\n",
    "        vocab_size = len(vocab)\n",
    "        g = np.zeros((vocab_size, vocab_size), dtype='float')\n",
    "        for word1, word2 in token_pairs:\n",
    "            i, j = vocab[word1], vocab[word2]\n",
    "            g[i][j] = 1\n",
    "\n",
    "        # Get Symmeric matrix\n",
    "        g = self.symmetrize(g)\n",
    "\n",
    "        # Normalize matrix by column\n",
    "        norm = np.sum(g, axis=0)\n",
    "        g_norm = np.divide(g, norm, where=norm!=0) # this is ignore the 0 element in norm\n",
    "\n",
    "        return g_norm\n",
    "\n",
    "\n",
    "    def get_keywords(self, number=10):\n",
    "        \"\"\"Print top number keywords\"\"\"\n",
    "        keysw={}\n",
    "        node_weight = OrderedDict(sorted(self.node_weight.items(), key=lambda t: t[1], reverse=True))\n",
    "        for i, (key, value) in enumerate(node_weight.items()):\n",
    "            keysw[key] =value\n",
    "            if i > number:\n",
    "                break\n",
    "        return keysw\n",
    "\n",
    "\n",
    "    def analyze(self, text,\n",
    "                candidate_pos=['NOUN', 'PROPN'],\n",
    "                window_size=4, lower=False, stopwords=list()):\n",
    "        \"\"\"Main function to analyze text\"\"\"\n",
    "\n",
    "        # Set stop words\n",
    "        self.set_stopwords(stopwords)\n",
    "\n",
    "        # Pare text by spaCy\n",
    "        doc = nlp(text)\n",
    "\n",
    "        # Filter sentences\n",
    "        sentences = self.sentence_segment(doc, candidate_pos, lower) # list of list of words\n",
    "\n",
    "        # Build vocabulary\n",
    "        vocab = self.get_vocab(sentences)\n",
    "\n",
    "        # Get token_pairs from windows\n",
    "        token_pairs = self.get_token_pairs(window_size, sentences)\n",
    "\n",
    "        # Get normalized matrix\n",
    "        g = self.get_matrix(vocab, token_pairs)\n",
    "\n",
    "        # Initionlization for weight(pagerank value)\n",
    "        pr = np.array([1] * len(vocab))\n",
    "\n",
    "        # Iteration\n",
    "        previous_pr = 0\n",
    "        for epoch in range(self.steps):\n",
    "            pr = (1-self.d) + self.d * np.dot(g, pr)\n",
    "            if abs(previous_pr - sum(pr))  < self.min_diff:\n",
    "                break\n",
    "            else:\n",
    "                previous_pr = sum(pr)\n",
    "\n",
    "        # Get weight for each node\n",
    "        node_weight = dict()\n",
    "        for word, index in vocab.items():\n",
    "            node_weight[word] = pr[index]\n",
    "\n",
    "        self.node_weight = node_weight\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de la función Grado de Fractalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solamente se calcula el grado de fractalidad de las palabras que tengan mas de uno de frecuencia\n",
    "def fractalidad(palabras,vocabulario,frec,dist):\n",
    "    N=len(palabras)                                     #El número de tokens de todo el texto\n",
    "    gf={}\n",
    "    cajas_index=set()\n",
    "    voc=[]                                             #la variable voc contendra cada sintagma con frecuencia mayor que 1, por que las otras palabras tendrán 0 de grado de fractaldiad\n",
    "    for p in vocabulario:                              #Esto se puede hacer fuera del algoritmo, pero se incluye para evitar ese calculo innecesario\n",
    "        if(p not in voc):\n",
    "            if(frec[p]>1):\n",
    "                if(p not in STOP_WORDS):\n",
    "                    if(len(p)>1):\n",
    "                        voc.append(p)\n",
    "    # print(\"Text size: \",N)\n",
    "    # print(\"Vocabulary: \",len(voc))\n",
    "    for p in voc:\n",
    "        rcajas=dist[p]\n",
    "        M=frec[p]\n",
    "        dfw=0.0\n",
    "        nsh=0.0\n",
    "        for s in range(1,N+1):\n",
    "            noc=0\n",
    "            for e in rcajas:\n",
    "                cajas_index.add(ceil(int(e)/s))\n",
    "            noc=len(cajas_index)\n",
    "            cajas_index.clear()\n",
    "            ns=N/s\n",
    "            if(M<=ns):\n",
    "                nsh=M\n",
    "            else:\n",
    "                nsh=M/(1+(M-1)/(N-1)*(s-1))\n",
    "            dfw=dfw+fabs(log(nsh/noc))\n",
    "        gf[p]=dfw\n",
    "    return gf    #regresamos un diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribucion(palabras,vocabulario):\n",
    "    N=len(palabras)\n",
    "    ncajas=[]\n",
    "    cajas={}\n",
    "    frecuencias={}\n",
    "    for p in vocabulario:\n",
    "        ncajas.clear()\n",
    "        i=0\n",
    "        M=palabras.count(p)\n",
    "        while(i<N):\n",
    "            if(p == palabras[i]):\n",
    "                ncajas.append(i+1)\n",
    "            i=i+1\n",
    "        frecuencias[p]=M\n",
    "        cajas[p]=ncajas[:]\n",
    "    return frecuencias,cajas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de archivo de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de archivo para generación de vocabulario\n",
    "def cargar_datos(filename):\n",
    "    textopos = []\n",
    "    textoneg =[]\n",
    "    with open(filename, encoding=\"utf-8-sig\") as f:\n",
    "        texto = pd.read_csv(f)\n",
    "        for _, r in texto.iterrows():\n",
    "            if r['ds0'] == 1:\n",
    "                textoneg.append(r['Texto'])\n",
    "            elif r['ds5']==1:\n",
    "                textopos.append(r['Texto'])\n",
    "        for row in textopos:\n",
    "            #Pasar a minusculas\n",
    "            row = ' '.join(row)\n",
    "            row = row.lower()\n",
    "    #Eliminar puntuación\n",
    "        for row in textoneg:\n",
    "            row = ' '.join(row)\n",
    "            row = row.lower()\n",
    "    textopos =' '.join(textopos)\n",
    "    textoneg=' '.join(textoneg)\n",
    "    textopos = textopos.translate(str.maketrans('', '', string.punctuation))\n",
    "    textoneg = textoneg.translate(str.maketrans('', '', string.punctuation))\n",
    "    textopos = textopos.translate(str.maketrans('', '', '¿?¡!.:,;—“”0123456789’'))\n",
    "    textoneg = textoneg.translate(str.maketrans('', '', '¿?¡!.:,;—“”0123456789’'))\n",
    "    palabraspos = textopos.split()\n",
    "    palabrasneg = textoneg.split()\n",
    "    textop=\"\"\n",
    "    texton=\"\"\n",
    "    #rearmamos el texto debido a que existen carácteres especiales\n",
    "    for w in palabraspos:\n",
    "        textop=textop+w+' '\n",
    "    for w in palabrasneg:\n",
    "        texton=texton+w+' '\n",
    "    return textop, texton"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lee_documento(filename='NULL',texto=''):\n",
    "    if filename != 'NULL':\n",
    "        textop, texton=cargar_datos(filename)\n",
    "    textop = textop.lower()\n",
    "    texton = texton.lower()\n",
    "    #obtenemos el vocabulario\n",
    "    tokensp=textop.split()\n",
    "    vocabulariop=[]\n",
    "    vocabularion=[]\n",
    "    tokensn = texton.split()\n",
    "    for t in tokensp:\n",
    "        if(t not in vocabulariop):\n",
    "            vocabulariop.append(t)\n",
    "    for t in tokensn:\n",
    "        if(t not in vocabularion):\n",
    "            vocabularion.append(t)\n",
    "    #variables de procesamiento\n",
    "    distp={}\n",
    "    distn={}\n",
    "    frecn={}\n",
    "    frecp={}\n",
    "    frecp,distp=distribucion(tokensp,vocabulariop)\n",
    "    frecn, distn = distribucion(tokensn, vocabularion)\n",
    "    return frecp,distp,tokensp,vocabulariop,textop,frecn,distn,tokensn,vocabularion,texton"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecución de algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de documento para el corpus de suicidio\n",
    "frecp,distp,tokensp,vocabulariop,textop,frecn,distn,tokensn,vocabularion,texton = lee_documento('/home/m/MGP/maestria/proyecto_tesis/baseline/Datasets/SMS_DATA_ORIGINAL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frecuencias: 8070\n",
      "Distribuciones:  8070\n",
      "Tokens:  101671\n",
      "Vocabulario:  8070\n",
      "Texto:  544467\n"
     ]
    }
   ],
   "source": [
    "print('Frecuencias:', len(frecp))\n",
    "print(\"Distribuciones: \", len(distp))\n",
    "print(\"Tokens: \", len(tokensp))\n",
    "print('Vocabulario: ', len(vocabulariop))\n",
    "print('Texto: ', len(textop))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frecuencias: 3349\n",
      "Distribuciones:  3349\n",
      "Tokens:  25052\n",
      "Vocabulario:  3349\n",
      "Texto:  130002\n"
     ]
    }
   ],
   "source": [
    "print('Frecuencias:', len(frecn))\n",
    "print(\"Distribuciones: \", len(distn))\n",
    "print(\"Tokens: \", len(tokensn))\n",
    "print('Vocabulario: ', len(vocabularion))\n",
    "print('Texto: ', len(texton))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grado de Fractalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ejecución de algoritmo Grado de Fractalidad\n",
    "def grado_de_fractalidad(tokens,vocabulario,frec,dist,regresa_kw=False,regresa_df=True,top_n=np.inf,escribe_arch=False):\n",
    "    frac_x=fractalidad(tokens,vocabulario,frec,dist)\n",
    "    sorted_x = sorted(frac_x.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    # print('Time GF: '+str(elapsed_time))\n",
    "\n",
    "    #Imprimir y guardar resultados de GF\n",
    "    if regresa_df:\n",
    "        if top_n != np.inf:\n",
    "            df=[[t[0],frec[t[0]], t[1], t[1]*log10(frec[t[0]])] for t in sorted_x[:top_n]]\n",
    "        else:\n",
    "            df=[[t[0],frec[t[0]], t[1], t[1]*log10(frec[t[0]])] for t in sorted_x]\n",
    "        #Ordenar resultados por medida combinada\n",
    "        df.sort(key=lambda x: x[3],reverse=True)\n",
    "        if regresa_kw==False:\n",
    "            df = [dato[0] for dato in df]\n",
    "            by_MC=pd.DataFrame(df, columns=['word'])\n",
    "        else:\n",
    "            by_MC=pd.DataFrame(df, columns=['word','frecuency','Degree_of_fractality','Combined_measure'])\n",
    "        if escribe_arch:\n",
    "            by_MC.to_csv('GF.csv')\n",
    "    else:\n",
    "        if top_n != np.inf:\n",
    "            df=[[t[0],frec[t[0]], t[1], t[1]*log10(frec[t[0]])] for t in sorted_x[:top_n]]\n",
    "        else:\n",
    "            df=[[t[0],frec[t[0]], t[1], t[1]*log10(frec[t[0]])] for t in sorted_x]\n",
    "        #Ordenar resultados por medida combinada\n",
    "        df.sort(key=lambda x: x[3],reverse=True)\n",
    "        if regresa_kw==False:\n",
    "            by_MC = [dato[0] for dato in df]\n",
    "        else:\n",
    "            by_MC = df\n",
    "        if escribe_arch:\n",
    "            print('\\nNo se tiene implementada la escritura de archivo cuando regresa_df==False\\n')\n",
    "    return by_MC\n",
    "\n",
    "def use_gf(texto,regresa_kw=False,regresa_df=False,top_n=np.inf,escribe_arch=False):\n",
    "    tokens=texto.split()\n",
    "    vocabulario=[]\n",
    "    for t in tokens:\n",
    "        if(t not in vocabulario):\n",
    "            vocabulario.append(t)\n",
    "    #variables de procesamiento\n",
    "    dist={}\n",
    "    frec={}\n",
    "    frec,dist=distribucion(tokens,vocabulario)\n",
    "    df = grado_de_fractalidad(tokens,vocabulario,frec,dist,regresa_kw,regresa_df,top_n,escribe_arch)\n",
    "    return df\n",
    "\n",
    "fractPositivas = use_gf(textop,regresa_kw=True,regresa_df=True,top_n=338)\n",
    "fractNegativas = use_gf(texton,regresa_kw=True,regresa_df=True,top_n=338)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frecuency</th>\n",
       "      <th>Degree_of_fractality</th>\n",
       "      <th>Combined_measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>caca</td>\n",
       "      <td>23</td>\n",
       "      <td>85221.880907</td>\n",
       "      <td>116049.007469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok</td>\n",
       "      <td>12</td>\n",
       "      <td>78526.466331</td>\n",
       "      <td>84744.289783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>capsulas</td>\n",
       "      <td>11</td>\n",
       "      <td>78681.018360</td>\n",
       "      <td>81937.836981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>observaciones</td>\n",
       "      <td>19</td>\n",
       "      <td>63249.000502</td>\n",
       "      <td>80879.887149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calzoncillo</td>\n",
       "      <td>11</td>\n",
       "      <td>77619.128001</td>\n",
       "      <td>80831.992129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>calificación</td>\n",
       "      <td>2</td>\n",
       "      <td>40944.423056</td>\n",
       "      <td>12325.499495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>ceac</td>\n",
       "      <td>2</td>\n",
       "      <td>40941.650467</td>\n",
       "      <td>12324.664863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>tdh</td>\n",
       "      <td>2</td>\n",
       "      <td>40939.571026</td>\n",
       "      <td>12324.038888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>cabezada</td>\n",
       "      <td>2</td>\n",
       "      <td>40932.639554</td>\n",
       "      <td>12321.952307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>escalar</td>\n",
       "      <td>2</td>\n",
       "      <td>40922.935493</td>\n",
       "      <td>12319.031094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              word  frecuency  Degree_of_fractality  Combined_measure\n",
       "0             caca         23          85221.880907     116049.007469\n",
       "1               ok         12          78526.466331      84744.289783\n",
       "2         capsulas         11          78681.018360      81937.836981\n",
       "3    observaciones         19          63249.000502      80879.887149\n",
       "4      calzoncillo         11          77619.128001      80831.992129\n",
       "..             ...        ...                   ...               ...\n",
       "333   calificación          2          40944.423056      12325.499495\n",
       "334           ceac          2          40941.650467      12324.664863\n",
       "335            tdh          2          40939.571026      12324.038888\n",
       "336       cabezada          2          40932.639554      12321.952307\n",
       "337        escalar          2          40922.935493      12319.031094\n",
       "\n",
       "[338 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fractPositivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frecuency</th>\n",
       "      <th>Degree_of_fractality</th>\n",
       "      <th>Combined_measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ángel</td>\n",
       "      <td>10</td>\n",
       "      <td>18176.971038</td>\n",
       "      <td>18176.971038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tío</td>\n",
       "      <td>18</td>\n",
       "      <td>12706.403384</td>\n",
       "      <td>15949.998807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vómitos</td>\n",
       "      <td>7</td>\n",
       "      <td>16922.938652</td>\n",
       "      <td>14301.542286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>auriculares</td>\n",
       "      <td>9</td>\n",
       "      <td>14084.868778</td>\n",
       "      <td>13440.380528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dolorido</td>\n",
       "      <td>10</td>\n",
       "      <td>12965.076868</td>\n",
       "      <td>12965.076868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>posibilidad</td>\n",
       "      <td>2</td>\n",
       "      <td>8582.483759</td>\n",
       "      <td>2583.585049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>lleno</td>\n",
       "      <td>2</td>\n",
       "      <td>8506.172169</td>\n",
       "      <td>2560.612971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>chantaje</td>\n",
       "      <td>2</td>\n",
       "      <td>8473.865898</td>\n",
       "      <td>2550.887815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>intranquila</td>\n",
       "      <td>2</td>\n",
       "      <td>8452.220467</td>\n",
       "      <td>2544.371891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>devuelto</td>\n",
       "      <td>2</td>\n",
       "      <td>8414.682102</td>\n",
       "      <td>2533.071717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  frecuency  Degree_of_fractality  Combined_measure\n",
       "0          ángel         10          18176.971038      18176.971038\n",
       "1            tío         18          12706.403384      15949.998807\n",
       "2        vómitos          7          16922.938652      14301.542286\n",
       "3    auriculares          9          14084.868778      13440.380528\n",
       "4       dolorido         10          12965.076868      12965.076868\n",
       "..           ...        ...                   ...               ...\n",
       "333  posibilidad          2           8582.483759       2583.585049\n",
       "334        lleno          2           8506.172169       2560.612971\n",
       "335     chantaje          2           8473.865898       2550.887815\n",
       "336  intranquila          2           8452.220467       2544.371891\n",
       "337     devuelto          2           8414.682102       2533.071717\n",
       "\n",
       "[338 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fractNegativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guarda los resultados del grado de fractalidad en un CSV. Siempre hay que cambiar la versión y comentar para no sobreescribir\n",
    "# fractPositivas.to_csv('/home/m/MGP/maestria/proyecto_tesis/baseline/output/fractalidad_etiqueta5_prueba1.csv')\n",
    "# fractNegativas.to_csv('/home/m/MGP/maestria/proyecto_tesis/baseline/output/fractalidad_etiqueta0_prueba1.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambio del máximo de tamaño de texto para que quepa el corpus (1.3 millones)\n",
    "nlp.max_length = 1500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ejecución de algoritmo de TextRank\n",
    "# start_time = time()\n",
    "def use_TextRank(texto,regresa_kw=False,regresa_df=False,top_n=np.inf,escribe_arch=False):\n",
    "    tr4w = TextRank4Keyword()\n",
    "    tr4w.analyze(texto, candidate_pos = ['NOUN','PROPN'], window_size=4, lower=False)\n",
    "    kwTR=tr4w.get_keywords(100)\n",
    "\n",
    "    #Guardar resultados de TextRank\n",
    "    if regresa_df:\n",
    "        if top_n!=np.inf:\n",
    "            if regresa_kw==True:\n",
    "                salida = [[key, kwTR[key]] for key in kwTR.keys()][:top_n]\n",
    "                dftr=pd.DataFrame(salida, columns=['word', 'Index'])\n",
    "            else:\n",
    "                salida = list(kwTR.keys())[:top_n]\n",
    "                dftr=pd.DataFrame(salida, columns=['word'])\n",
    "        else:\n",
    "            if regresa_kw==True:\n",
    "                salida = [[key, kwTR[key]] for key in kwTR.keys()]\n",
    "                dftr=pd.DataFrame(salida, columns=['word', 'Index'])\n",
    "            else:\n",
    "                salida = list(kwTR.keys())\n",
    "                dftr=pd.DataFrame(salida, columns=['word'])\n",
    "    else:\n",
    "        if top_n!=np.inf:\n",
    "            if regresa_kw==True:\n",
    "                dftr = [[key, kwTR[key]] for key in kwTR.keys()][:top_n]\n",
    "            else:\n",
    "                dftr = list(kwTR.keys())[:top_n]\n",
    "        else:\n",
    "            if regresa_kw==True:\n",
    "                dftr = [[key, kwTR[key]] for key in kwTR.keys()]\n",
    "            else:\n",
    "                dftr = list(kwTR.keys())\n",
    "        # elapsed_time = time() - start_time\n",
    "        # print('Time TextRank: '+str(elapsed_time))\n",
    "        if escribe_arch:\n",
    "            dftr.to_csv('TextRank.csv')\n",
    "    return dftr\n",
    "\n",
    "trpos = use_TextRank(textop,top_n=338)\n",
    "trneg = use_TextRank(texton,top_n=338)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trabajo',\n",
       " 'cosas',\n",
       " 'casa',\n",
       " 'semana',\n",
       " 'tiempo',\n",
       " 'vida',\n",
       " 'ansiedad',\n",
       " 'horas',\n",
       " 'noche',\n",
       " 'familia',\n",
       " 'mañana',\n",
       " 'ganas',\n",
       " 'problemas',\n",
       " 'madre',\n",
       " 'cabeza',\n",
       " 'situación',\n",
       " 'sueño',\n",
       " 'problema',\n",
       " 'momento',\n",
       " 'tratamiento',\n",
       " 'miedo',\n",
       " 'medicación',\n",
       " 'sensación',\n",
       " 'ánimo',\n",
       " 'dolor',\n",
       " 'hora',\n",
       " 'gente',\n",
       " 'general',\n",
       " 'años',\n",
       " 'marido',\n",
       " 'mujer',\n",
       " 'pareja',\n",
       " 'persona',\n",
       " 'gracias',\n",
       " 'cosa',\n",
       " 'padre',\n",
       " 'momentos',\n",
       " 'hija',\n",
       " 'tema',\n",
       " 'consulta',\n",
       " 'cuestionario',\n",
       " 'doctora',\n",
       " 'forma',\n",
       " 'cita',\n",
       " 'mes',\n",
       " 'vacaciones',\n",
       " 'cambio',\n",
       " 'comida',\n",
       " 'médico',\n",
       " 'intento',\n",
       " 'tensión',\n",
       " 'hijo',\n",
       " 'hermana',\n",
       " 'amigos',\n",
       " 'semanas',\n",
       " 'nervios',\n",
       " 'pastillas',\n",
       " 'hijos',\n",
       " 'niño',\n",
       " 'pensamientos',\n",
       " 'falta',\n",
       " 'baja',\n",
       " 'sábado',\n",
       " 'relación',\n",
       " 'lunes',\n",
       " 'rato',\n",
       " 'amiga',\n",
       " 'cambios',\n",
       " 'dolores',\n",
       " 'hospital',\n",
       " 'año',\n",
       " 'cansancio',\n",
       " 'sigo',\n",
       " 'estrés',\n",
       " 'viernes',\n",
       " 'cuerpo',\n",
       " 'meses',\n",
       " 'madrid',\n",
       " 'discusión',\n",
       " 'enfermedad',\n",
       " 'domingo',\n",
       " 'salud',\n",
       " 'psiquiatra',\n",
       " 'personas',\n",
       " 'mañanas',\n",
       " 'gusto',\n",
       " 'preocupación',\n",
       " 'test',\n",
       " 'ayuda',\n",
       " 'fuerzas',\n",
       " 'compañeros',\n",
       " 'viaje',\n",
       " 'resto',\n",
       " 'mente',\n",
       " 'circunstancias',\n",
       " 'empresa',\n",
       " 'razón',\n",
       " 'actividad',\n",
       " 'miligramo',\n",
       " 'coche',\n",
       " 'hermano',\n",
       " 'confianza']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vida',\n",
       " 'ansiedad',\n",
       " 'ganas',\n",
       " 'cabeza',\n",
       " 'dolor',\n",
       " 'casa',\n",
       " 'madre',\n",
       " 'cosas',\n",
       " 'noche',\n",
       " 'tiempo',\n",
       " 'mierda',\n",
       " 'horas',\n",
       " 'miedo',\n",
       " 'problemas',\n",
       " 'mundo',\n",
       " 'cosa',\n",
       " 'medicación',\n",
       " 'semana',\n",
       " 'cama',\n",
       " 'trabajo',\n",
       " 'persona',\n",
       " 'mañana',\n",
       " 'comida',\n",
       " 'dolores',\n",
       " 'años',\n",
       " 'familia',\n",
       " 'daño',\n",
       " 'culpa',\n",
       " 'situación',\n",
       " 'pena',\n",
       " 'hospital',\n",
       " 'fuerzas',\n",
       " 'hija',\n",
       " 'año',\n",
       " 'gente',\n",
       " 'momento',\n",
       " 'padre',\n",
       " 'hora',\n",
       " 'cuerpo',\n",
       " 'nervios',\n",
       " 'voces',\n",
       " 'personas',\n",
       " 'problema',\n",
       " 'cita',\n",
       " 'gracias',\n",
       " 'sueño',\n",
       " 'pesadillas',\n",
       " 'médico',\n",
       " 'tío',\n",
       " 'cambio',\n",
       " 'sigo',\n",
       " 'atracones',\n",
       " 'tensión',\n",
       " 'mente',\n",
       " 'hijos',\n",
       " 'discusiones',\n",
       " 'pastillas',\n",
       " 'caso',\n",
       " 'sensación',\n",
       " 'asco',\n",
       " 'hermano',\n",
       " 'amiga',\n",
       " 'chocolate',\n",
       " 'doctora',\n",
       " 'pensamientos',\n",
       " 'consulta',\n",
       " 'decisión',\n",
       " 'pruebas',\n",
       " 'resto',\n",
       " 'calle',\n",
       " 'discusión',\n",
       " 'maría',\n",
       " 'baja',\n",
       " 'sentido',\n",
       " 'ángel',\n",
       " 'jueves',\n",
       " 'mujer',\n",
       " 'pareja',\n",
       " 'domingo',\n",
       " 'noches',\n",
       " 'amigos',\n",
       " 'enfermedad',\n",
       " 'lorazepam',\n",
       " 'falta',\n",
       " 'coche',\n",
       " 'tipo',\n",
       " 'ayuda',\n",
       " 'sábado',\n",
       " 'peso',\n",
       " 'seguridad',\n",
       " 'pecho',\n",
       " 'puta',\n",
       " 'piernas',\n",
       " 'alta',\n",
       " 'moral',\n",
       " 'meses',\n",
       " 'hijo',\n",
       " 'trato',\n",
       " 'duermo',\n",
       " 'depresión',\n",
       " 'atracón',\n",
       " 'voz']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guarda los resultados del TextRank en un txt. Siempre hay que cambiar la versión y comentar para no sobreescribir\n",
    "# with open('/home/m/MGP/maestria/proyecto_tesis/baseline/output/TextRank_resultados_etiqueta5_prueba1.txt','w') as output:\n",
    "#     output.write(str(trpos))\n",
    "# with open('/home/m/MGP/maestria/proyecto_tesis/baseline/output/TextRank_resultado_setiqueta0_prueba1.txt','w') as output:\n",
    "#     output.write(str(trneg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación de los resultados de fractalidad y TextRank con el conjunto de Palabras Prototípicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/m/MGP/maestria/proyecto_tesis/baseline/Palabras_proto/clinical-prescores.csv', encoding=\"utf-8-sig\") as f:\n",
    "        palabrasProto = pd.read_csv(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>word</th>\n",
       "      <th>c-prescore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>lormetazepam</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mg</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>mirtazapina</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>fluoxetina</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>alprazolam</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>334</td>\n",
       "      <td>aclaratorio</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>335</td>\n",
       "      <td>limpié</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>336</td>\n",
       "      <td>practicas</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>337</td>\n",
       "      <td>claros</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>338</td>\n",
       "      <td>convierte</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>339 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0          word  c-prescore\n",
       "0             0  lormetazepam        -5.0\n",
       "1             1            mg        -5.0\n",
       "2             2   mirtazapina        -5.0\n",
       "3             3    fluoxetina        -5.0\n",
       "4             4    alprazolam        -5.0\n",
       "..          ...           ...         ...\n",
       "334         334   aclaratorio         2.0\n",
       "335         335        limpié         2.0\n",
       "336         336     practicas         2.0\n",
       "337         337        claros         2.0\n",
       "338         338     convierte         2.0\n",
       "\n",
       "[339 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palabrasProto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para crear la medida de Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Medida Jaccard que mide la proporción de elementos de un conjunto en otro\n",
    "def jaccard(s1: set, s2: set):\n",
    "    return len(s1 & s2) / len(s1 | s2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coinsidencia(conjuntoA, conjuntoB):\n",
    "    matches = []\n",
    "    for palabra in conjuntoA:\n",
    "        if palabra in conjuntoB:\n",
    "            matches.append(palabra)\n",
    "    conteo = len(matches)\n",
    "    return matches, conteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard de fractalidad positivas:  0.024205748865355523\n",
      "Jaccard de TextRank positivas:  0.02320185614849188\n",
      "Jaccard de fractalidad negativas:  0.035168195718654434\n",
      "Jaccard de TextRank negativas:  0.018475750577367205\n"
     ]
    }
   ],
   "source": [
    "jaccFractalidadPos = jaccard(set(palabrasProto['word']), set(fractPositivas['word']))\n",
    "jaccTRPos = jaccard(set(palabrasProto['word']), set(trpos))\n",
    "jaccFractalidadNeg = jaccard(set(palabrasProto['word']), set(fractNegativas['word']))\n",
    "jaccTRNeg = jaccard(set(palabrasProto['word']), set(trneg))\n",
    "# _, conteosTR = jaccard(texto, dftr)\n",
    "# _, conteosFract= jaccard(texto, list(df1['word']))\n",
    "# _, conteosProto= jaccard(texto, list(palabrasProto['Palabra']))\n",
    "\n",
    "print('Jaccard de fractalidad positivas: ', jaccFractalidadPos)\n",
    "\n",
    "print('Jaccard de TextRank positivas: ', jaccTRPos)\n",
    "\n",
    "\n",
    "print('Jaccard de fractalidad negativas: ', jaccFractalidadNeg)\n",
    "\n",
    "print('Jaccard de TextRank negativas: ', jaccTRNeg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "coinTRPos, conteoTRPos= coinsidencia(list(palabrasProto['word']), trpos)\n",
    "coinTRNeg, conteoTRNeg = coinsidencia(list(palabrasProto['word']), trneg)\n",
    "coinFracPos, conteoFracPos = coinsidencia(list(palabrasProto['word']), list(fractPositivas['word']))\n",
    "coinFracNeg, conteoFracNeg = coinsidencia(list(palabrasProto['word']), list(fractNegativas['word']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo TR positivas: 10\n",
      "Conteo TR negativas: 8\n",
      "Conteo Fractalidad positivas: 16\n",
      "Conteo Fractalidad negativas: 23\n"
     ]
    }
   ],
   "source": [
    "print('Conteo TR positivas:', conteoTRPos)\n",
    "print('Conteo TR negativas:', conteoTRNeg)\n",
    "print('Conteo Fractalidad positivas:', conteoFracPos)\n",
    "print('Conteo Fractalidad negativas:', conteoFracNeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Siguientes pasos\n",
    "\n",
    "- Probar sólo con una etiqueta: ✅\n",
    "- Hacer una prueba con BeRT como viene usando los embedings de BETO y la tarea con un KeyBERT: ✅\n",
    "- Hacer una prueba con KeyBERT haciendo un finetuning de los embedings de BETO\n",
    "- Hablar con Ulises para ver la propuesta de la LSTM con atención\n",
    "- Hacer un análisis de las palabras prototípicas utilizadas con la base de datos de prototipicalidad\n",
    "- Hacer una prueba con un LLM (preguntar si con la API o directamente) y evaluar resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
